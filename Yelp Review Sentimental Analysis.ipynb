{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Multinomial Naive Bayes Algorithm to Classify Yelp Sentimental Review Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to build the sentimental classifier with accuracy higher than 80% using the multinomial Naive Bayes algorithm. We will compare the probability for a word and if the proability of a positive category is greater than the one of a negative category, then this word will be classified as a positive word. By combining all proabilities of words within a sentence/comment, we will get the whole comment proability and be able to identify the sentimental categories (positive or negative). \n",
    "\n",
    "The data used in this study is from https://www.kaggle.com/rahulin05/sentiment-labelled-sentences-data-set . \n",
    "\n",
    "Note that this project is inspired by one of the Guided Projects of DataQuest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  category\n",
       "0                           Wow... Loved this place.         1\n",
       "1                                 Crust is not good.         0\n",
       "2          Not tasty and the texture was just nasty.         0\n",
       "3  Stopped by during the late May bank holiday of...         1\n",
       "4  The selection on the menu was great and so wer...         1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the file \n",
    "yp = pd.read_csv('yelp_labelled.txt', delimiter = \"\\t\", header=None)\n",
    "yp.columns = ['comment','category']\n",
    "yp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Category/Label**\n",
    "- A negative comment: 0\n",
    "- A positive comment: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50.0\n",
       "0    50.0\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentages of positive and negative\n",
    "yp['category'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp.shape[0] # how many tweet in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 2)\n",
      "(200, 2)\n"
     ]
    }
   ],
   "source": [
    "randomized_yp = yp.sample(frac=1, random_state=1)\n",
    "idx = round((randomized_yp.shape[0])*0.8) # 80% train, 20% test\n",
    "train = randomized_yp[:idx].reset_index(drop=True)\n",
    "test = randomized_yp[idx:].reset_index(drop=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50.0\n",
       "0    50.0\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['category'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50.0\n",
       "0    50.0\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['category'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we made sure that we have similar percentages of sentiment in both train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower Letter Case and Remove Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier for further analysis, we will remove the punctuation and make all words to become lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my gyro was basically lettuce only</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it kept getting worse and worse so now i m off...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am far from a sushi connoisseur but i can de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the staff are great  the ambiance is great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>by this time our side of the restaurant was al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  category\n",
       "0                my gyro was basically lettuce only          0\n",
       "1  it kept getting worse and worse so now i m off...         0\n",
       "2  i am far from a sushi connoisseur but i can de...         0\n",
       "3        the staff are great  the ambiance is great          1\n",
       "4  by this time our side of the restaurant was al...         0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment'] = train['comment'].str.replace('\\W',' ')\n",
    "train['comment'] = train['comment'].str.lower()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Volcabulary List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[my, gyro, was, basically, lettuce, only]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[it, kept, getting, worse, and, worse, so, now...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[i, am, far, from, a, sushi, connoisseur, but,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[the, staff, are, great, the, ambiance, is, gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[by, this, time, our, side, of, the, restauran...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  category\n",
       "0          [my, gyro, was, basically, lettuce, only]         0\n",
       "1  [it, kept, getting, worse, and, worse, so, now...         0\n",
       "2  [i, am, far, from, a, sushi, connoisseur, but,...         0\n",
       "3  [the, staff, are, great, the, ambiance, is, gr...         1\n",
       "4  [by, this, time, our, side, of, the, restauran...         0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment'] = train['comment'].str.split() # split the text to get the list of words\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all the words in the vocab list\n",
    "vocab = []\n",
    "for comment in train['comment']:\n",
    "    for word in comment:\n",
    "        vocab.append(word)\n",
    "\n",
    "# remove duplicates\n",
    "vocab = set(vocab)\n",
    "vocabulary = list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['six', 'crab', 'attached', 'see', 'did']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing Word Counts in Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_comment = {unique_word: [0]*len(train['comment']) for unique_word in vocabulary}\n",
    "\n",
    "for idx, comment in enumerate(train['comment']):\n",
    "    for word in comment:\n",
    "        word_counts_per_comment[word][idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>six</th>\n",
       "      <th>crab</th>\n",
       "      <th>attached</th>\n",
       "      <th>see</th>\n",
       "      <th>did</th>\n",
       "      <th>dark</th>\n",
       "      <th>return</th>\n",
       "      <th>lover</th>\n",
       "      <th>crowd</th>\n",
       "      <th>happened</th>\n",
       "      <th>...</th>\n",
       "      <th>old</th>\n",
       "      <th>famous</th>\n",
       "      <th>meats</th>\n",
       "      <th>diverse</th>\n",
       "      <th>likes</th>\n",
       "      <th>huevos</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>traditional</th>\n",
       "      <th>filling</th>\n",
       "      <th>cranberry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1791 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   six  crab  attached  see  did  dark  return  lover  crowd  happened  ...  \\\n",
       "0    0     0         0    0    0     0       0      0      0         0  ...   \n",
       "1    0     0         0    0    0     0       0      0      0         0  ...   \n",
       "2    0     0         0    0    0     0       0      0      0         0  ...   \n",
       "\n",
       "   old  famous  meats  diverse  likes  huevos  restaurant  traditional  \\\n",
       "0    0       0      0        0      0       0           0            0   \n",
       "1    0       0      0        0      0       0           0            0   \n",
       "2    0       0      0        0      0       0           0            0   \n",
       "\n",
       "   filling  cranberry  \n",
       "0        0          0  \n",
       "1        0          0  \n",
       "2        0          0  \n",
       "\n",
       "[3 rows x 1791 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_comment = pd.DataFrame(word_counts_per_comment)\n",
    "word_counts_per_comment.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>category</th>\n",
       "      <th>six</th>\n",
       "      <th>crab</th>\n",
       "      <th>attached</th>\n",
       "      <th>see</th>\n",
       "      <th>did</th>\n",
       "      <th>dark</th>\n",
       "      <th>return</th>\n",
       "      <th>lover</th>\n",
       "      <th>...</th>\n",
       "      <th>old</th>\n",
       "      <th>famous</th>\n",
       "      <th>meats</th>\n",
       "      <th>diverse</th>\n",
       "      <th>likes</th>\n",
       "      <th>huevos</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>traditional</th>\n",
       "      <th>filling</th>\n",
       "      <th>cranberry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[my, gyro, was, basically, lettuce, only]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[it, kept, getting, worse, and, worse, so, now...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[i, am, far, from, a, sushi, connoisseur, but,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1793 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  category  six  crab  \\\n",
       "0          [my, gyro, was, basically, lettuce, only]         0    0     0   \n",
       "1  [it, kept, getting, worse, and, worse, so, now...         0    0     0   \n",
       "2  [i, am, far, from, a, sushi, connoisseur, but,...         0    0     0   \n",
       "\n",
       "   attached  see  did  dark  return  lover  ...  old  famous  meats  diverse  \\\n",
       "0         0    0    0     0       0      0  ...    0       0      0        0   \n",
       "1         0    0    0     0       0      0  ...    0       0      0        0   \n",
       "2         0    0    0     0       0      0  ...    0       0      0        0   \n",
       "\n",
       "   likes  huevos  restaurant  traditional  filling  cranberry  \n",
       "0      0       0           0            0        0          0  \n",
       "1      0       0           0            0        0          0  \n",
       "2      0       0           0            0        0          0  \n",
       "\n",
       "[3 rows x 1793 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the word_counts_per_text dataframe to train set\n",
    "train = pd.concat([train, word_counts_per_comment], axis=1)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Calulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probality equation that we can use to classify new comments (eqn.1):\n",
    "\n",
    "$$P(Sentimental \\space Category \\space A|New \\space Comment) = \\frac{P(Sentimental \\space Category \\space A)\\cdot P(New \\space Comment|Sentimental \\space Category \\space A)}{P(New \\space Comment)}$$      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to compare only the results of the all 2 group using the eqn.1, we can remove the division to make the calulation become easier, and it will not affect the final calssification decision. The equations of all three catgories will be reduced to:\n",
    "\n",
    "$$ P(Positive|New \\space Comment) \\space \\alpha \\space  P(Positive)\\cdot P(New \\space Comment|Positive)$$\n",
    "$$ P(Negative|New \\space Comment) \\space \\alpha \\space P(Negative)\\cdot P(New \\space Comment|Negative)$$\n",
    "\n",
    "Note that by reducing the equation, the calculated probabilities will not be accurate anymore. However, we still can compare individual calculated values to classify the sentimental category of new comments, which is our main goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to find a probability of each sentimental catgory given a new comment, which is consisting of many words. This can be expressed as the following (eqn.2):\n",
    "\n",
    "$$ P(Category \\space A| w_1,w_2,...,w_n) = \\frac{P(Category \\space A \\space \\cap \\space (w_1,w_2,...,w_n))}{P(w_1,w_2,...,w_n)}$$\n",
    "\n",
    "where $w_1, w_2, w_3,...,w_n$ are words within that comment.\n",
    "\n",
    "\n",
    "To make calulation easier, we reduce eqn.2 to (eqn.3):\n",
    "\n",
    "$$ P(Category \\space A| w_1,w_2,...,w_n) \\space \\alpha \\space P(Category \\space A \\cap (w_1,w_2,...,w_n))$$\n",
    "\n",
    "\n",
    "Here we make an assumption that all the words are conditionally independent. This is why we call this algorithm Naive Bayes since it's a simple way to make an assumption of conditional independece and do the calulations. However, this is not always the case in reality, and it's likely that words are dependent.\n",
    "\n",
    "In this study, we assume conditional indepence between words. Thus, the eqn.3 can be written as follow (eqn.4):\n",
    "\n",
    "$$ P(Category \\space A| w_1,w_2,...,w_n) \\space \\alpha \\space P(w_1|Category \\space A)\\cdot P(w_2|Category \\space A) \\cdot P(w_3|Category \\space A) \\cdot \\space \\dots  \\space \\cdot P(w_n|Category \\space A)$$\n",
    "\n",
    "\n",
    "The eqn.4 can be written in this form as well (eqn.5):\n",
    "\n",
    "$$ P(Category \\space A| w_1,w_2,...,w_n) \\space \\alpha \\space P(Category \\space A)\\cdot \\prod_{i=1}^{n} P(w_i|Category \\space A) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate $P(w_i|Category \\space A)$, we will use the following equation (eqn.6):\n",
    "\n",
    "$$ P(w_i|Category \\space A) = \\frac{N_{w_i|Category \\space A}+\\alpha}{N_{Category \\space A} + \\alpha \\cdot N_{Vocabulary}}$$\n",
    "\n",
    "where \n",
    "- $N_{w_i|Category \\space A}$ = number of times that the word ($w_i$) occurs in Category A comments\n",
    "- $N_{Category \\space A}$ = total number of words in Category A comments\n",
    "- $N_{Vocabulary}$ = total number of words in the vocabulary (list of unique words found in the dataset)\n",
    "- $\\alpha$ = a smoothing parameter or Laplace/Additive smoothing. This parameter is assigned to 1, and it helps to solve an issue when a word is not found in comments of a certain sentimental category. For example, we want to calculate P(Positive|'I am not a bad person') and \"bad\" is not in the Positive comments, so P('bad'|Positive) is zero. And because of that, using eqn. 4 P(Positive|'I am not a bad person') becomes zero as well. This shows that if only one word is not in comments of a certain sentimental category, it can affect the calculated proability and leads to wrong classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract individual sentimental comments\n",
    "pos_comment = train[train['category']==1]\n",
    "neg_comment = train[train['category']==0]\n",
    "\n",
    "# calculate probabilities of the individuals\n",
    "p_pos = len(pos_comment)/len(train)\n",
    "p_neg = len(neg_comment)/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of all words (not just unique) in all 3 groups, plus in vocabulary \n",
    "n_pos = pos_comment['comment'].apply(len).sum()\n",
    "n_neg = neg_comment['comment'].apply(len).sum()\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "## use Laplace smoothing and assign alpha = 1\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_probs = {unique_word:0 for unique_word in vocabulary}\n",
    "neg_probs = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "# using eqn.6\n",
    "for word in vocabulary:\n",
    "    n_word_given_pos = pos_comment[word].sum()\n",
    "    p_word_given_pos = (n_word_given_pos + alpha)/(n_pos + alpha*n_vocabulary)\n",
    "    pos_probs[word] = p_word_given_pos\n",
    "\n",
    "    n_word_given_neg = neg_comment[word].sum()\n",
    "    p_word_given_neg = (n_word_given_neg + alpha)/(n_neg + alpha*n_vocabulary)\n",
    "    neg_probs[word] = p_word_given_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def classify(comment):\n",
    "    comment = re.sub('\\W', ' ', comment)\n",
    "    comment = comment.lower()\n",
    "    comment = comment.split()\n",
    "    \n",
    "    p_pos_given_comment = p_pos\n",
    "    p_neg_given_comment = p_neg\n",
    "    for word in comment:\n",
    "        if word in pos_probs:\n",
    "            p_pos_given_comment *= pos_probs[word]\n",
    "        if word in neg_probs:\n",
    "            p_neg_given_comment *= neg_probs[word]\n",
    "    \n",
    "    if p_pos_given_comment > p_neg_given_comment:\n",
    "        return 1\n",
    "    elif p_neg_given_comment > p_pos_given_comment:\n",
    "        return 0\n",
    "    else: \n",
    "        return -1 # cannot classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentimental Classifier Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_accuracy(df):\n",
    "    correct = 0\n",
    "    total = df.shape[0]\n",
    "    \n",
    "    for row in df.iterrows():\n",
    "        row = row[1]\n",
    "        if row['category'] == row['predicted']:\n",
    "            correct += 1\n",
    "\n",
    "    print(\"Accuracy: \", round(correct*100/total,2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tonight I had the Elk Filet special...and it s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What a mistake.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I asked multiple times for the wine list and a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My friend loved the salmon tartar.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If someone orders two tacos don't' you think i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  category  predicted\n",
       "0  Tonight I had the Elk Filet special...and it s...         0          0\n",
       "1                                    What a mistake.         0          0\n",
       "2  I asked multiple times for the wine list and a...         0          0\n",
       "3                 My friend loved the salmon tartar.         1          1\n",
       "4  If someone orders two tacos don't' you think i...         0          0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['predicted'] = test['comment'].apply(classify)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  84.0 %\n"
     ]
    }
   ],
   "source": [
    "classify_accuracy(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Other Dataset Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_classify(df, frac_train_test_split):\n",
    "    randomized_df = df.sample(frac=1, random_state=1)\n",
    "    idx = round((randomized_df.shape[0])*frac_train_test_split) \n",
    "    train = randomized_df[:idx].reset_index(drop=True)\n",
    "    test = randomized_df[idx:].reset_index(drop=True)\n",
    "    \n",
    "    train['comment'] = train['comment'].str.replace('\\W',' ')\n",
    "    train['comment'] = train['comment'].str.lower()\n",
    "    train['comment'] = train['comment'].str.split()\n",
    "    \n",
    "    # create vocabulary\n",
    "    vocab = []\n",
    "    for comment in train['comment']:\n",
    "        for word in comment:\n",
    "            vocab.append(word)\n",
    "    vocab = set(vocab)\n",
    "    vocabulary = list(vocab)\n",
    "    \n",
    "    # store word counts in dictionary \n",
    "    word_counts_per_comment = {unique_word: [0]*len(train['comment']) for unique_word in vocabulary}\n",
    "    for idx, comment in enumerate(train['comment']):\n",
    "        for word in comment:\n",
    "            word_counts_per_comment[word][idx] += 1\n",
    "\n",
    "    # concatnate all the unique words to the dataframe\n",
    "    word_counts_per_comment = pd.DataFrame(word_counts_per_comment)\n",
    "    train = pd.concat([train, word_counts_per_comment], axis=1)\n",
    "    \n",
    "    ## Probability calculations\n",
    "    # extract individual sentimental comments\n",
    "    pos_comment = train[train['category']==1]\n",
    "    neg_comment = train[train['category']==0]\n",
    "\n",
    "    # calculate probabilities of the individuals\n",
    "    p_pos = len(pos_comment)/len(train)\n",
    "    p_neg = len(neg_comment)/len(train)\n",
    "    \n",
    "    # calculate number of all words (not just unique) in all 3 groups, plus in vocabulary \n",
    "    n_pos = pos_comment['comment'].apply(len).sum()\n",
    "    n_neg = neg_comment['comment'].apply(len).sum()\n",
    "    n_vocabulary = len(vocabulary)\n",
    "\n",
    "    ## use Laplace smoothing and assign alpha = 1\n",
    "    alpha = 1\n",
    "    \n",
    "    pos_probs = {unique_word:0 for unique_word in vocabulary}\n",
    "    neg_probs = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "    # using eqn.6\n",
    "    for word in vocabulary:\n",
    "        n_word_given_pos = pos_comment[word].sum()\n",
    "        p_word_given_pos = (n_word_given_pos + alpha)/(n_pos + alpha*n_vocabulary)\n",
    "        pos_probs[word] = p_word_given_pos\n",
    "\n",
    "        n_word_given_neg = neg_comment[word].sum()\n",
    "        p_word_given_neg = (n_word_given_neg + alpha)/(n_neg + alpha*n_vocabulary)\n",
    "        neg_probs[word] = p_word_given_neg\n",
    "    \n",
    "    # predict the category\n",
    "    test['predicted'] = test['comment'].apply(classify)\n",
    "    \n",
    "    # calculate and return the accuracy\n",
    "    return classify_accuracy(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's try our function with Amazon dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  74.0 %\n",
      "Accuracy:  74.8 %\n",
      "Accuracy:  76.5 %\n",
      "Accuracy:  77.33 %\n",
      "Accuracy:  78.0 %\n"
     ]
    }
   ],
   "source": [
    "# import and change the column names\n",
    "amz = pd.read_csv('amazon_cells_labelled.txt', delimiter = \"\\t\", header=None)\n",
    "amz.columns = ['comment','category']\n",
    "\n",
    "# run the classification function\n",
    "frac_train_test_split = [0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "\n",
    "for r in frac_train_test_split:\n",
    "    accuracy = sentiment_classify(amz, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Although we reached our goal getting higher accuracy than expectation (80%) for Yelp review dataset, when we apply our function with different dataset, i.e. Amazon reviews, the accuracy decreases. It's possible that we do not have enough words in vocabulary list since when we change train set to be larger, the accuracy increases. If we have more data, this may help improving our model performance.\n",
    "- For future work, we can take a look at individual comments that their actual categories are not the same as our predictions, and may be able to improve our model based on that observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
